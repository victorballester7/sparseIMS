\documentclass{article}
\usepackage[top=2.5cm, bottom=2.5cm, left=3cm, right=3cm]{geometry}
\usepackage{lmodern}
\pagestyle{empty}
\usepackage{preamble_math}
\usepackage{hyperref}
\usepackage{caption}
\usepackage[backend=biber,style=alphabetic]{biblatex}
\addbibresource{references.bib} % your .bib file
\usepackage{bm}
\usepackage{parskip} % exchanges indentation for spacing between paragraphs.

% change link colour
\hypersetup{
	colorlinks=true,
	linkcolor=blue,
	filecolor=magenta,      
	urlcolor=blue,
	citecolor=blue,
}

\title{\textbf{Numerical Linear Algebra and Sparse Matrices}}
\date{}
\author{
\begin{tabular}{@{}l@{\hspace{0.8cm}}r@{}}
Víctor Ballester Ribó & v.ballester-ribo24@imperial.ac.uk \\
Joseph Whitaker Schaefer & j.schaefer24@imperial.ac.uk \\
\end{tabular}
\vspace{0.5cm}\\\textsc{Department of Aeronautics}\\\textsc{Imperial College London}}

% remove page numbers
\pagenumbering{gobble}


% remove indentation
\setlength{\parindent}{0pt}

\defbibheading{subbibcustom}{\paragraph*{References}}

\begin{document}

\maketitle

We live in a world driven by matrices - Equations describing global economies, AI models, computer graphics, and more are regularly posed and solved in matrix form. A matrix can be defined as the mathematical object used to represent a system of linear equations. Here are a few examples:
\begin{align*}
	                & \quad\;\, y = 3x + 2              & \begin{pmatrix}
		                                                      y
	                                                      \end{pmatrix}
	                & =
	\begin{pmatrix}
		3
	\end{pmatrix}
	\begin{pmatrix}
		x
	\end{pmatrix}
	+
	\begin{pmatrix}
		2
	\end{pmatrix} & \text{1-dimensional matrix}                          \\
	\\
	                & \begin{cases}
		                  y_1 = 4x_1 + 2x_2 + 7 \\
		                  y_2 = -x_1 + 2
	                  \end{cases}          &
	\begin{pmatrix}
		y_1 \\
		y_2
	\end{pmatrix}
	                & =
	\begin{pmatrix}
		4  & 2 \\
		-1 & 0
	\end{pmatrix}
	\begin{pmatrix}
		x_1 \\
		x_2
	\end{pmatrix}
	+
	\begin{pmatrix}
		7 \\
		2
	\end{pmatrix} & \text{2-dimensional matrix}                          \\
	\\
	                & \begin{cases}
		                  y_1 = 7x_1 + x_2 - 1/2 x_3 + 2 \\
		                  y_2 = 4x_1 - 5x_3              \\
		                  y_3 = 3/2x_1 + 3x_2 - 4x_3 + 1
	                  \end{cases} &
	\begin{pmatrix}
		y_1 \\
		y_2 \\
		y_3
	\end{pmatrix}
	                & =
	\begin{pmatrix}
		7   & 1 & -1/2 \\
		4   & 0 & -5   \\
		3/2 & 3 & -4
	\end{pmatrix}
	\begin{pmatrix}
		x_1 \\
		x_2 \\
		x_3
	\end{pmatrix}
	+
	\begin{pmatrix}
		2 \\
		0 \\
		1
	\end{pmatrix} & \text{3-dimensional matrix}
\end{align*}
In practice, the vector in the left-hand side of the equations is known, and so we need to find the vector $\bm{x}$ by solving the system of equations
\begin{equation*}
	\bm{y} = \bm{A} \bm{x} + \bm{b}.
\end{equation*}
Since $\bm{y}$ is known, we can replace $\bm{y}-\bm{b}$ by a new, and also known, vector $\bm{\tilde{y}}$ and solve for $\bm{x}$ in the system
\begin{equation*}
	\bm{\tilde{y}} = \bm{A} \bm{x}.
\end{equation*}
This implies we can just consider the problem of solving homogeneous systems of equations, where $\bm{b} = \bm{0}$.

A first approach to solve these systems might be to extend the classical definition of inverse of a number ($\frac{1}{a} \cdot a = a\cdot \frac{1}{a}  = 1$) to matrices, and then use the inverse of $\bm{A}$ to find $\bm{x}$ as
\begin{equation*}
	\bm{x} = (\bm{A}^{-1}  \bm{A}) \bm{x} = \bm{A}^{-1} ( \bm{A} \bm{x}) = \bm{A}^{-1} \bm{\tilde{y}}.
\end{equation*}
We will see that this approach is not efficient for large size matrices. An alternative approach is to use the Gaussian elimination method, which consists of isolting every variable in terms of the next ones. For example in the 3-dimensional matrix example above, we can isolate $x_1$ in the first equation as
\begin{equation*}
	x_1 = 1/7(y_1 - x_2 + 1/2 x_3 - 2),
\end{equation*}
and then substitute this expression in the second and third equations to obtain a system of two equations with two unknowns. Then, isolate $x_2$, as a function of $x_3$, in one of the two resulting equations and introduce it to the remaining equation to obtain a linear system of one equation with one unknown. Finally, we can isolate $x_3$ and substitute it back in the previous equations to find $x_2$ and $x_1$.

The first aim of this project will explore and implement some of the many advanced methods for solving systems of matrix equations in a programming language of your choice.

The second aim will be to extend this work to cover some forms of sparse matrices, a matrix in which most of the elements are zero. See the example below of a sparse linear system of dimension $n$:

\begin{equation*}
	\begin{pmatrix}
		y_1     \\
		y_2     \\
		\vdots  \\
		y_{n-1} \\
		y_n
	\end{pmatrix} =
	\begin{pmatrix}
		2      & -1     & 0      & \cdots & 0      \\
		-1     & 2      & -1     & \ddots & \vdots \\
		0      & \ddots & \ddots & \ddots & 0      \\
		\vdots & \ddots & -1     & 2      & -1     \\
		0      & \cdots & 0      & -1     & 2
	\end{pmatrix}
	\begin{pmatrix}
		x_1     \\
		x_2     \\
		\vdots  \\
		x_{n-1} \\
		x_n
	\end{pmatrix}.
\end{equation*}

The density (e.g.\ number of non-zero elements divided by the total number of elements) of this matrix is $\frac{3n-2}{n^2}$, which tends to $0$ as $n$ goes to infinity. Because of this, using the same algorithms as for dense (e.g.\ matrices with many non-zero elements) matrices is not efficient, taking into account the prior knowledge of the null values. Contrary to what one might think, sparse matrices are used in many applications, such as solving differential equations (e.g.\ heating up your cup of milk) or graphs theory (e.g.\ finding the best route through Google Maps).

In this part of the project we will use algorithms specifically designed to solve sparse matrices, and the comparison of the performance of these algorithms with the ones used for dense matrices, in terms of the density of the matrix and the size of the matrix.

This project will suit students with interested in growing their applied mathematics experience through the formulation and implementation of algorithms for scientific computing. Interest in low-level (C, Rust, C\texttt{++}, \dots) or  high-level (Python, Matlab, Julia, \dots) programming languages is useful, but not essential.

Below are materials regarding general numerical linear algebra~\cite{linalg} and sparse matrices~\cite{sparse} for further reading.

\printbibliography[heading=subbibcustom]
\end{document}
end{document}
